#!/usr/bin/python

import sys, os, os.path, string, glob, math
import random
import time
import datetime
import tempfile
import subprocess
import unittest
import argparse
import StringIO

from wallabyclient.exceptions import *
from wallabyclient import WallabyHelpers, WallabyTypes
from qmf.console import Session
from condorutils.osutil import run_cmd


class grid_scale_test_params:
    def __init__(self):
        self.broker_addr = '127.0.0.1'
        self.port = 5672
        self.passwd = ''
        self.username = ''
        self.mechanisms = 'ANONYMOUS PLAIN GSSAPI'
        self.supported_api_versions = {20100804:0, 20100915:0, 20101031:1}
        self.package = 'com.redhat.grid.config'
        self.no_restore = False


# A structure to provide params to unit tests
params = grid_scale_test_params()


# A base class for our unit tests -- defines snapshot/restore for the pool
class grid_scale_test(unittest.TestCase):
    def connect_to_wallaby_store(self):
        # To do: I wanted to default this in a constructor, but need to figure out what PyUnit
        # expects for constructor of unittest.TestCase.
        if not self.__dict__.has_key('params'):
            # Get it from global variable
            self.params = params

        # set up session for wallaby
        self.session = Session()

        if self.params.username != '' and self.params.passwd != '':
            broker_str = '%s/%s@%s:%d' % (self.params.username, self.params.passwd, self.params.broker_addr, self.params.port)
        elif self.params.username != '':
            broker_str = '%s@%s:%d' % (self.params.username, self.params.broker_addr, self.params.port)
        else:
            broker_str = '%s:%d' % (self.params.broker_addr, self.params.port)

        sys.stdout.write("Connecting to broker %s:\n" % (broker_str))

        try:
            self.broker = self.session.addBroker('amqp://%s' % broker_str, mechanisms=self.params.mechanisms)
        except:
            sys.stderr.write('Unable to connect to broker "%s"\n' % broker_str)
            raise

        # Retrieve the config store object
        sys.stdout.write("Connecting to wallaby store:\n")
        try:
            (self.store_agent, self.config_store) = WallabyHelpers.get_store_objs(self.session)
        except WallabyStoreError, error:
            sys.stderr.write('Error: %s\n' % error.error_str)
            self.session.delBroker(self.broker)
            raise

        # Check API version number
        try:
            WallabyHelpers.verify_store_api(self.config_store, self.params.supported_api_versions)
        except WallabyUnsupportedAPI, error:
            if error.minor == 0:
                store_api_version = error.major
            else:
                store_api_version = '%s.%s' % (error.major, error.minor)
            sys.stderr.write('The store is using an API version that is not supported (%s)\n' % store_api_version)
            self.session.delBroker(self.broker)
            raise

    def take_snapshot(self, name):
        sys.stdout.write("Snapshotting current pool config to %s:\n" % (name))
        result = self.config_store.makeSnapshot(name)
        if result.status != 0:
            sys.stderr.write("Failed to snapshot current pool to %s: (%d, %s)\n" % (name, result.status, result.text))
            raise WallabyStoreError(result.text)
        sys.stdout.write("Finished config snapshot %s\n" % (name))

    def load_snapshot(self, name):
        sys.stdout.write("Restoring pool config from %s:\n" % (name))
        result = self.config_store.loadSnapshot(name)
        if result.status != 0:
            sys.stderr.write("Failed to restore from %s: (%d, %s)\n" % (name, result.status, result.text))
            raise WallabyStoreError(result.text)
        sys.stdout.write("Finished restoring snapshot %s\n" % (name))


    def setUp(self):
        self.setup = False

        self.devnull = open(os.devnull, 'rw')

        self.connect_to_wallaby_store()

        try:
            sys.stdout.write("Obtaining nodes from config store:\n")
            node_list = self.store_agent.getObjects(_class='Node', _package=self.params.package)

            sys.stdout.write("Obtaining groups from config store:\n")
            group_list = self.store_agent.getObjects(_class='Group', _package=self.params.package)

            sys.stdout.write("Obtaining features from config store:\n")
            feat_list = self.store_agent.getObjects(_class='Feature', _package=self.params.package)

            sys.stdout.write("Obtaining params from config store:\n")
            param_list = self.store_agent.getObjects(_class='Parameter', _package=self.params.package)
        except:
            sys.stderr.write("Failed to obtain data from current config store\n")
            raise

        self.node_names = [x.name for x in node_list]
        self.group_names = [x.name for x in group_list]
        self.feat_names = [x.name for x in feat_list]
        self.param_names = [x.name for x in param_list]

        self.testdate = time.strftime("%Y/%m/%d_%H:%M:%S")
        self.snapshot = "grid_scale_%s_pretest" % (self.testdate)
        self.take_snapshot(self.snapshot)


    def tearDown(self):
        if self.params.no_restore:
            sys.stdout.write("WARNING: NOT restoring pre-test snapshot %s\n" % (self.snapshot))
        else:
            self.load_snapshot(self.snapshot)

            # Activate restored config
            result = self.config_store.activateConfiguration(_timeout=600)
            if result.status != 0:
                sys.stderr.write("Failed to activate restored configuration %s: (%s, %s)\n" % (self.snapshot, result.status, result.text))
                raise Exception(result.text)

        self.session.delBroker(self.broker)


    def assert_param(self, param_name):
        if not param_name in self.param_names:
            sys.stdout.write("Adding parameter %s to store:\n" % (param_name))
            result = self.config_store.addParam(param_name)
            if result.status != 0:
                sys.stderr.write("Failed to add param %s: (%d, %s)\n" % (param_name, result.status, result.text))
                raise WallabyStoreError("Failed to add param")
            self.param_names += [param_name]


    def assert_feature(self, feature_name):
        if not feature_name in self.feat_names:
            result = self.config_store.addFeature(feature_name)
            if result.status != 0:
                sys.stderr.write("Failed to add feature %s: (%s, %s)\n" % (feature_name, result.status, result.text))
                raise WallabyStoreError(result.text)
            self.feat_names += [feature_name]


    def assert_group_features(self, feature_names, group_names):
        # ensure these actually exist
        for grp in group_names:
            if not grp in self.group_names:
                sys.stdout.write("Adding group %s to store:\n" % (grp))
                result = self.config_store.addExplicitGroup(grp)
                if result.status != 0:
                    sys.stderr.write("Failed to create group %s: (%d, %s)\n" % (grp, result.status, result.text))
                    raise WallabyStoreError(result.text)

        # In principle, could automatically install features if they aren't found
        for feat in feature_names:
            if not feat in self.feat_names: raise Exception("Feature %s not in config store" % (feat))

        # apply feature list to group
        for name in group_names:
            group_obj = WallabyHelpers.get_group(self.session, self.config_store, name)
            result = group_obj.modifyFeatures('replace', feature_names, {})
            if result.status != 0:
                sys.stderr.write("Failed to set features for %s: (%d, %s)\n" % (name, result.status, result.text))
                raise WallabyStoreError(result.text)


    def assert_node_features(self, feature_names, node_names):
        for feat in feature_names:
            if not feature_name in self.feat_names: raise Exception("Feature %s not in config store" % (feat))

        # apply feature list to nodes
        for name in node_names:
            node_obj = WallabyHelpers.get_node(self.session, self.config_store, name)
            group_name = WallabyHelpers.get_id_group_name(node_obj, self.session)
            group_obj = WallabyHelpers.get_group(self.session, self.config_store, group_name)
            result = group_obj.modifyFeatures('replace', feature_names, {})
            if result.status != 0:
                sys.stderr.write("Failed to set features for %s: (%d, %s)\n" % (name, result.status, result.text))
                raise WallabyStoreError(result.text)


    def assert_node_groups(self, group_names, node_names):
        # apply the groups to the nodes
        for name in node_names:
            node_obj = WallabyHelpers.get_node(self.session, self.config_store, name)
            result = node_obj.modifyMemberships('replace', group_names, {})
            if result.status != 0:
                sys.stderr.write("Failed to set groups for %s: (%d, %s)\n" % (name, result.status, result.text))
                raise WallabyStoreError(result.text)


    def clear_nodes(self, node_names):
        for name in node_names:
            node_obj = WallabyHelpers.get_node(self.session, self.config_store, name)
            result = node_obj.modifyMemberships('replace', [], {})
            if result.status != 0:
                sys.stderr.write("Failed to clear groups from %s: (%d, %s)\n" % (name, result.status, result.text))
                raise WallabyStoreError("Failed to clear groups")

            group_name = WallabyHelpers.get_id_group_name(node_obj, self.session)
            group_obj = WallabyHelpers.get_group(self.session, self.config_store, group_name)
            result = group_obj.modifyFeatures('replace', [], {})
            if result.status != 0:
                sys.stderr.write("Failed to clear features from %s: (%d, %s)\n" % (name, result.status, result.text))
                raise WallabyStoreError("Failed to clear features")

            result = group_obj.modifyParams('replace', {}, {})
            if result.status != 0:
                sys.stderr.write("Failed to clear params from %s: (%d, %s)\n" % (name, result.status, result.text))
                raise WallabyStoreError("Failed to clear params")


    def tag_test_feature(self, feature_name, param_name):
        # ensure parameter name exists
        self.assert_param(param_name)

        # ensure that parameter requires restart
        param_obj = WallabyHelpers.get_param(self.session, self.config_store, param_name)
        result = param_obj.setRequiresRestart(True)
        if result.status != 0:
            sys.stderr.write("Failed to set restart for %s: (%d, %s)\n" % (param_name, result.status, result.text))
            raise WallabyStoreError("Failed to set restart")

        # set this param to a new value, to ensure a restart on activation
        feat_obj = WallabyHelpers.get_feature(self.session, self.config_store, feature_name)
        result = feat_obj.modifyParams('add', {param_name:("%s"%(time.time()))}, {})
        if result.status != 0:
            sys.stderr.write("Failed to add param %s to %s: (%d, %s)\n" % (param_name, feature_name, result.status, result.text))
            raise WallabyStoreError("Failed to add param")

        # make sure master is tagged for restart via this parameter
        subsys_obj = WallabyHelpers.get_subsys(self.session, self.config_store, 'master')
        result = subsys_obj.modifyParams('add', [param_name], {})
        if result.status != 0:
            sys.stderr.write("Failed to add param %s to master: (%d, %s)\n" % (param_name, result.status, result.text))
            raise WallabyStoreError("Failed to add param")


    def poll_for_slots(self, nslots, group=None, interval=30, maxtime=600):
        if group == None:
            status_cmd = "condor_status -subsystem startd -format \"%s\\n\" Name | wc -l"
        else:
            status_cmd = "condor_status -subsystem startd -format \"%%s\\n\" Name -constraint 'stringListMember(\"%s\", WallabyGroups)' | wc -l" % (group)
        t0 = time.time()
        while (True):
            sys.stdout.write("Waiting %d seconds for %d slots " % (interval, nslots))
            if group != None: sys.stdout.write("from group %s " % (group))
            sys.stdout.write("to spool up:\n")
            time.sleep(interval)
            try:
                res = subprocess.Popen(["/bin/sh", "-c", status_cmd], stdout=subprocess.PIPE, stderr=self.devnull).communicate()[0]
                res = res.strip()
                n = int(res)
            except:
                n = 0
            elapsed = time.time() - t0
            # stop waiting if we see we have the desired number of configured startds
            sys.stdout.write("elapsed= %d sec  slots= %d:\n" % (int(elapsed), n))
            if n >= nslots: break
            if (elapsed > maxtime): raise Exception("Exceeded max polling time")


    def poll_for_empty_job_queue(self, cluster=None, tag=None, tagvar="GridScaleTestTag", interval=30, maxtime=600):
        if cluster != None:
            q_cmd = "condor_q -format \"%%s\\n\" GlobalJobId -constraint 'ClusterId==%d'| wc -l" % (cluster)
        elif tag != None:
            q_cmd = "condor_q -format \"%%s\\n\" GlobalJobId -constraint '%s==\"%s\"'| wc -l" % (tagvar, tag)
        else:
            q_cmd = "condor_q -format \"%s\\n\" GlobalJobId | wc -l"

        try:
            # get an initial job count.
            res = subprocess.Popen(["/bin/sh", "-c", q_cmd], stdout=subprocess.PIPE, stderr=self.devnull).communicate()[0]
            n0 = int(res)
        except:
            n0 = 999999
        t0 = time.time()
        while (True):
            sys.stdout.write("Waiting %s seconds for job que to clear " % (interval))
            if cluster != None: sys.stdout.write("for cluster %d " % (cluster))
            elif tag != None: sys.stdout.write("for %s==\"%s\"" % (tagvar, tag))
            sys.stdout.write("\n")
            time.sleep(interval)
            try:
                res = subprocess.Popen(["/bin/sh", "-c", q_cmd], stdout=subprocess.PIPE, stderr=self.devnull).communicate()[0]
                n = int(res)
            except:
                n = n0
            elapsed = time.time() - t0
            sys.stdout.write("elapsed= %d seconds   jobs= %d   cum-complete-rate= %f:\n" % (int(elapsed), n, float(n0-n)/float(elapsed)))
            # stop waiting when que is clear of specified jobs
            if n <= 0: break
            if (elapsed > maxtime): raise Exception("Exceeded max polling time")


    def list_nodes(self, with_all_feats=None, without_any_feats=None, with_all_groups=None, without_any_groups=None):
        r = []
        for node in self.node_names:
            node_obj = WallabyHelpers.get_node(self.session, self.config_store, node)

            nodefeats = []
            if (with_all_feats != None) or (without_any_feats != None):
                nodefeats = WallabyHelpers.get_node_features(node_obj, self.session, self.config_store)
            if (with_all_feats != None) and (False in [x in nodefeats for x in with_all_feats]): continue
            if (without_any_feats != None) and (True in [x in nodefeats for x in without_any_feats]): continue

            nodegroups = []
            if (with_all_groups != None) or (without_any_groups != None):
                nodegroups = [WallabyHelpers.get_id_group_name(node_obj, self.session)] + node_obj.memberships + ['+++DEFAULT']
            if (with_all_groups != None) and (False in [x in nodegroups for x in with_all_groups]): continue
            if (without_any_groups != None) and (True in [x in nodegroups for x in without_any_groups]): continue

            r += [node]
        return r


    def build_execute_feature(self, feature_name, n_startd=1, n_slots=1, n_dynamic=0, collector_host=None):
        self.assert_feature(feature_name)

        if collector_host==None: collector_host = self.params.broker_addr
        sys.stdout.write("building execute feature %s -- n_startd=%d  n_slots=%d  n_dynamic=%d\n"%(feature_name, n_startd, n_slots, n_dynamic))

        params={}
        params["USE_PROCD"] = "FALSE"
        params["COLLECTOR_HOST"] = collector_host
        params["ALLOW_WRITE"] = "*"
        params["ALLOW_READ"] = "*"
        params["SEC_DEFAULT_AUTHENTICATION_METHODS"] = "CLAIMTOBE"

        params["START"] = "TRUE"
        params["SUSPEND"] = "FALSE"
        params["KILL"] = "FALSE"
        params["CONTINUE"] = "TRUE"
        params["WANT_VACATE"] = "FALSE"
        params["WANT_SUSPEND"] = "FALSE"

        params["CLAIM_WORKLIFE"] = "0"
        params["MAXJOBRETIREMENTTIME"] = "3600 * 24"
        params["PREEMPT"] = "FALSE"
        params["PREEMPTION_REQUIREMENTS"] = "FALSE"
        params["RANK"] = "0"
        params["NEGOTIATOR_CONSIDER_PREEMPTION"] = "FALSE"

        if n_dynamic > 0:
            params["SLOT_TYPE_1"] = "cpus=%d"%(n_dynamic)
            params["SLOT_TYPE_1_PARTITIONABLE"] = "TRUE"
            params["NUM_SLOTS_TYPE_1"] = "%d"%(n_slots)
            params["NUM_CPUS"] = "%d"%(n_slots * n_dynamic)
        else:
            params["NUM_SLOTS"] = "%d"%(n_slots)
            params["NUM_CPUS"] = "%d"%(n_slots)

        daemon_list = "MASTER"
        for s in xrange(n_startd):
            tag = "ST%03d"%(s)
            daemon_list += ",STARTD_%s"%(tag)
            params["STARTD_%s"%(tag)] = "$(STARTD)"
            params["STARTD_%s_ARGS"%(tag)] = "-f -local-name %s"%(tag)
            params["STARTD.%s.STARTD_NAME"%(tag)] = "%s"%(tag)
            params["STARTD.%s.ADDRESS_FILE"%(tag)] = "$(LOG)/.%s-address"%(tag)
            params["STARTD.%s.STARTD_LOG"%(tag)] = "$(LOG)/%s_Log"%(tag)

        params["DAEMON_LIST"] = daemon_list

        # make sure parameters are declared
        for p in params.keys(): self.assert_param(p)

        feat_obj = WallabyHelpers.get_feature(self.session, self.config_store, feature_name)
        result = feat_obj.modifyParams('replace', params, {})
        if result.status != 0:
            sys.stderr.write("Failed to modify params for %s: (%d, %s)\n" % (feature_name, result.status, result.text))
            raise WallabyStoreError("Failed to add param")



# A prototype "micro" scale test, to run on a personal condor
class grid_scale_test_micro(grid_scale_test):
    def setUp(self):
        # parent class setup first:
        grid_scale_test.setUp(self)

        if len(self.node_names) < 1: raise Exception("Require at least one node in pool")
        target_node = self.node_names[0]
        sys.stdout.write("Target for test is: %s\n" % (target_node))

        self.assert_feature('GridScaleTestMicro')

        # define features on the given groups
        self.assert_group_features(['GridScaleTestMicro'], ['GridScaleTestMicro'])

        # This is my subversive technique for ensuring that my target systems restart
        self.tag_test_feature('GridScaleTestMicro', 'GRID_SCALE_TEST_RESTART_TAG')

        # Make sure all config is cleared from nodes
        self.clear_nodes([target_node])

        # define groups on the given nodes
        # For this 'micro' test, I'm assuming a personal condor that has
        # a configuration independent of wallaby -- in general, this would
        # require me to add basic functionality features, since I just cleared
        # everything above
        self.assert_node_groups(['GridScaleTestMicro'], [target_node])

        # snapshot this test config
        self.take_snapshot("grid_scale_%s_micro_test" % (self.testdate))

        # Activate new config
        result = self.config_store.activateConfiguration(_timeout=600)
        if result.status != 0:
            raise Exception("Failed to activate test configuration: (%s, %s)" % (result.status, result.text))

        # before we leave set-up, make sure activation and restart are complete
        self.poll_for_slots(1, group='GridScaleTestMicro', interval=10, maxtime=120)


    def tearDown(self):
        # Don't wait for jobs to complete, just nuke them
        subprocess.call(["condor_rm", "-constraint", "GridScaleTestTag==\"Micro\""], stdout=self.devnull, stderr=self.devnull)
        # Do wait for job queue to empty before restoration and reactivation
        self.poll_for_empty_job_queue(tag="Micro", interval=10, maxtime=120)

        # call base-class teardown after our class-specific work
        grid_scale_test.tearDown(self)


    def test_submit_rate(self):
        # this unit test should pass
        n = 100
        sys.stdout.write("Testing submission rate over %d individual submits:\n" % (n))
        t0 = time.time()
        for k in xrange(n):
            subprocess.Popen("condor_submit", stdin=subprocess.PIPE, stdout=self.devnull, stderr=self.devnull).communicate(input='universe = vanilla\nexecutable = /bin/sleep\narguments = 10m\nrequirements = (WallabyGroups == "GridScaleTestMicro")\n+GridScaleTestTag="Micro"\nqueue\n')
        elapsed = time.time() - t0
        sys.stdout.write("%f seconds for %d submits -> %f submissions / sec\n" % (elapsed, n, float(n)/float(elapsed)))
        


# small scale test
class grid_scale_test_small(grid_scale_test):
    def setUp(self):
        self.setup = False
        try:
            grid_scale_test.setUp(self)
        except:
            sys.stderr.write("setup failed")
            raise

        # class specific setup goes after parent class
        candidate_nodes = self.list_nodes(with_all_groups=['GridScaleTestNode'], without_any_feats=['CentralManager','Negotiator','Collector'])

        self.ntarget = 8
        if len(candidate_nodes) < self.ntarget:
            sys.stderr.write("%d nodes insufficient for this test\n" % (len(candidate_nodes)))
            raise Exception()

        # just take the first ones on the list
        self.target_nodes = candidate_nodes[:self.ntarget]
        sys.stdout.write("target_nodes: %s\n" % (self.target_nodes))

        self.assert_feature('GridScaleTestSmall')
        self.build_execute_feature('GridScaleTestSmallExecute', n_startd=8, n_slots=8, n_dynamic=0)

        # define features on the given groups
        self.assert_group_features(['NodeAccess', 'Master', 'GridScaleTestSmall', 'GridScaleTestSmallExecute'], ['GridScaleTestSmall'])

        # This is my subversive technique for ensuring that my target systems restart
        self.tag_test_feature('GridScaleTestSmall', 'GRID_SCALE_TEST_RESTART_TAG')

        # Make sure all config is cleared from nodes
        self.clear_nodes(self.target_nodes)

        # define groups on the given nodes
        self.assert_node_groups(['GridScaleTestSmall'], self.target_nodes)

        # snapshot this test config
        self.take_snapshot("grid_scale_%s_small_test" % (self.testdate))

        # Activate new config
        result = self.config_store.activateConfiguration(_timeout=600)
        if result.status != 0:
            raise Exception("Failed to activate test configuration: (%s, %s)" % (result.status, result.text))

        # before we leave set-up, make sure activation and restart are complete
        self.poll_for_slots(int((self.ntarget*8*8)/2), group='GridScaleTestSmall', interval=10, maxtime=120)

        # flag that all setup succeeded
        self.setup = True


    def tearDown(self):
        # class specific teardown goes before parent class
        grid_scale_test.tearDown(self)


    def test_submit_rate(self):
        if not self.setup:
            sys.stderr.write("setup failed")
            raise Exception()
        # this unit test should pass
        duration = 330
        maxreps = 300
        submit_procs = []
        for j in xrange(10):
            cjs_command = "~/git/condor_tools/bin/cjs -duration %d -xgroups U%03d 1 -reqs 'stringListMember(\"GridScaleTestSmall\", WallabyGroups)' -ss -ss-interval 1.0 -ss-maxreps %d >out%03d 2>err%03d" % (duration, j, maxreps, j, j)
            sys.stdout.write("spawning submit process \"%s\"\n" % (cjs_command))
            proc = subprocess.Popen(["/bin/sh", "-c", cjs_command], stdout=self.devnull, stderr=self.devnull)
            submit_procs += [proc]

        sys.stdout.write("Waiting for spawned submission processes to complete...\n")
        t0 = time.time()
        while True:
            time.sleep(1)
            completed = True
            for p in submit_procs:
                if p.poll() == None: completed = False
            if completed: break

        elapsed = time.time() - t0
        sys.stdout.write("elapsed time = %s\n" % (elapsed))


    def test_submit_and_complete(self):
        if not self.setup:
            sys.stderr.write("setup failed")
            raise Exception()
        # this unit test should pass
        duration = 330
        maxreps = 300
        submit_procs = []
        for j in xrange(10):
            cjs_command = "~/git/condor_tools/bin/cjs -duration %d -xgroups U%03d 1 -reqs 'stringListMember(\"GridScaleTestSmall\", WallabyGroups)' -append '+GridScaleTestTag=\"Small\"' -ss -ss-interval 1.0 -ss-maxreps %d >out%03d 2>err%03d" % (duration, j, maxreps, j, j)
            sys.stdout.write("spawning submit process \"%s\"\n" % (cjs_command))
            proc = subprocess.Popen(["/bin/sh", "-c", cjs_command], stdout=self.devnull, stderr=self.devnull)
            submit_procs += [proc]

        sys.stdout.write("Waiting for spawned submission processes to complete...\n")
        t0 = time.time()
        while True:
            time.sleep(1)
            completed = True
            for p in submit_procs:
                if p.poll() == None: completed = False
            if completed: break

        elapsed = time.time() - t0
        sys.stdout.write("elapsed time = %s\n" % (elapsed))
        delay = duration - elapsed
        sys.stdout.write("waiting %f secs for start of job completions\n" % (float(delay)))
        time.sleep(delay)

        # this waits for jobs to finish, and also measures completion rate
        self.poll_for_empty_job_queue(tag = "Small", interval = 30, maxtime=int(elapsed+duration))

        

# medium scale test
class grid_scale_test_medium(grid_scale_test):
    def setUp(self):
        grid_scale_test.setUp(self)
        # class specific setup goes after parent class

    def tearDown(self):
        # class specific teardown goes before parent class
        grid_scale_test.tearDown(self)
        
    def test1(self):
        # this unit test should pass
        sys.stdout.write("medium scale test: sleeping...\n")
        time.sleep(10)



# large scale test
class grid_scale_test_large(grid_scale_test):
    def setUp(self):
        grid_scale_test.setUp(self)
        # class specific setup goes after parent class

    def tearDown(self):
        # class specific teardown goes before parent class
        grid_scale_test.tearDown(self)
        
    def test1(self):
        # this unit test should pass
        sys.stdout.write("large scale test: sleeping...\n")
        time.sleep(10)



class grid_scale_test_4000(grid_scale_test):
    def setUp(self):
        self.setup = False
        try:
            grid_scale_test.setUp(self)
        except:
            sys.stderr.write("setup failed")
            raise

        # class specific setup goes after parent class
        candidate_nodes = self.list_nodes(with_all_groups=['GridScaleTestNode'], without_any_feats=['CentralManager','Negotiator','Collector'])

        self.ntarget = 10
        if len(candidate_nodes) < self.ntarget:
            sys.stderr.write("%d nodes insufficient for this test\n" % (len(candidate_nodes)))
            raise Exception()

        # just take the first ones on the list
        self.target_nodes = candidate_nodes[:self.ntarget]
        sys.stdout.write("target_nodes: %s\n" % (self.target_nodes))

        self.assert_feature('GridScaleTest4000')
        self.build_execute_feature('GridScaleTest4000Execute', n_startd=50, n_slots=1, n_dynamic=8)

        # define features on the given groups
        self.assert_group_features(['NodeAccess', 'Master', 'GridScaleTest4000', 'GridScaleTest4000Execute'], ['GridScaleTest4000'])

        # This is my subversive technique for ensuring that my target systems restart
        self.tag_test_feature('GridScaleTest4000', 'GRID_SCALE_TEST_RESTART_TAG')

        # Make sure all config is cleared from nodes
        self.clear_nodes(self.target_nodes)

        # define groups on the given nodes
        self.assert_node_groups(['GridScaleTest4000'], self.target_nodes)

        # snapshot this test config
        self.take_snapshot("grid_scale_%s_4000_test" % (self.testdate))

        # Activate new config
        result = self.config_store.activateConfiguration(_timeout=600)
        if result.status != 0:
            raise Exception("Failed to activate test configuration: (%s, %s)" % (result.status, result.text))

        # before we leave set-up, make sure activation and restart are complete
        #self.poll_for_slots(self.ntarget*8*8, group='GridScaleTestSmall', interval=30, maxtime=600)

        # flag that all setup succeeded
        self.setup = True


    def tearDown(self):
        # class specific teardown goes before parent class
        grid_scale_test.tearDown(self)


    def test_dummy(self):
        if not self.setup:
            sys.stderr.write("setup failed")
            raise Exception()



if __name__ == "__main__":
    # Intercept harness-specific args from command line
    ha_parser = argparse.ArgumentParser()
    ha_parser.add_argument('-b', '--broker', dest='broker_addr', default='127.0.0.1')
    ha_parser.add_argument('-o', '--port', type=int, dest='port', default=5672)
    ha_parser.add_argument('-P', '--password', dest='passwd', default='')
    ha_parser.add_argument('-U', '--user', dest='username', default='')
    ha_parser.add_argument('-m', '--auth-mechanism', dest='mechanisms', default='ANONYMOUS PLAIN GSSAPI')
    ha_parser.add_argument('--no-restore', dest='no_restore', action='store_true', default=False)
    # Tentatively, I don't think it's a good idea to run all test cases
    # So I'm making this a required positional param
    ha_parser.add_argument('test_name')

    # This parses command line args and loads defined args into object 'params'
    ha_parser.parse_args(sys.argv[1:], namespace=params)

    # Pass requested test name to PyUnit
    sys.argv = sys.argv[:1]
    sys.argv += [params.test_name]

    # This provides nice default command-line facilities for running
    # any unit tests defined in this module/command.
    unittest.main()
